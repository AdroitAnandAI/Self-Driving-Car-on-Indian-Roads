{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acceleration Prediction using LeNet-inspired Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "To predict the acceleration of the vehicle based on the image frames in the video. \n",
    "\n",
    "We use the **3-layered Convnet Architecture design inspired by LeNet, 1998 paper by Le Cunn.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom-Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\ipykernel_launcher.py:26: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "c:\\python\\lib\\site-packages\\ipykernel_launcher.py:26: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    }
   ],
   "source": [
    "import scipy.misc\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "accels = []\n",
    "brake = []\n",
    "# gear = []\n",
    "opticalFlow = []\n",
    "\n",
    "#points to the end of the last batch\n",
    "train_batch_pointer = 0\n",
    "val_batch_pointer = 0\n",
    "corr_train_batch_pointer = 0\n",
    "corr_val_batch_pointer = 0\n",
    "\n",
    "dataPath = \"indian_dataset/\"\n",
    "corrDataPath = \"indian_dataset/corr/\"\n",
    "fileNamePrefix = \"circuit2_x264.mp4 \"\n",
    "\n",
    "\n",
    "with open(dataPath+\"data.txt\") as f:\n",
    "    for line in f:\n",
    "        xs.append(scipy.misc.imresize(scipy.misc.imread(\n",
    "            dataPath + fileNamePrefix + str(int(line.split()[0])).zfill(5)+\".jpg\")[-150:], [112, 112]) / 255.0)\n",
    "        #the paper by Nvidia uses the inverse of the turning radius,\n",
    "        #but steering wheel angle is proportional to the inverse of turning radius\n",
    "        #so the steering wheel angle in radians is used as the output\n",
    "        accels.append(float(line.split()[2])* scipy.pi / 180)\n",
    "\n",
    "\n",
    "#get number of images\n",
    "num_images = len(xs)\n",
    "\n",
    "# train_xs, train_accels, val_xs, val_accels\n",
    "train_xs = xs[:int(len(xs) * 0.8)]\n",
    "train_accels = accels[:int(len(xs) * 0.8)]\n",
    "\n",
    "val_xs = xs[-int(len(xs) * 0.2):]\n",
    "val_accels = accels[-int(len(xs) * 0.2):]\n",
    "\n",
    "# print(train_accels)\n",
    "# print(len(train_xs))\n",
    "\n",
    "# train_xs, train_accels, val_xs, val_accels\n",
    "train_xs = np.array(train_xs)\n",
    "train_accels = np.array(train_accels)\n",
    "\n",
    "val_xs = np.array(val_xs)\n",
    "val_accels = np.array(val_accels)\n",
    "\n",
    "input_shape = (112, 112, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: LeNet Inspired 3-Convolution Layer Architecture\n",
    "\n",
    "This 3-layered is different but inspired from the LeNet, 1998 paper by Le Cunn.\n",
    "\n",
    "http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf\n",
    "\n",
    "\n",
    "<img src=\"lenet.jpg\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23760 samples, validate on 5940 samples\n",
      "Epoch 1/30\n",
      "23760/23760 [==============================] - 72s 3ms/step - loss: 0.0027 - mean_squared_error: 0.0027 - mean_absolute_error: 0.0341 - mean_absolute_percentage_error: 665310.8763 - cosine_proximity: -0.9530 - val_loss: 0.0012 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0313 - val_mean_absolute_percentage_error: 1629.3925 - val_cosine_proximity: -1.0000\n",
      "Epoch 2/30\n",
      "23760/23760 [==============================] - 67s 3ms/step - loss: 9.8084e-04 - mean_squared_error: 9.8084e-04 - mean_absolute_error: 0.0266 - mean_absolute_percentage_error: 544773.0175 - cosine_proximity: -0.9415 - val_loss: 0.0012 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0303 - val_mean_absolute_percentage_error: 1744.3755 - val_cosine_proximity: -1.0000\n",
      "Epoch 3/30\n",
      "23760/23760 [==============================] - 66s 3ms/step - loss: 8.6685e-04 - mean_squared_error: 8.6685e-04 - mean_absolute_error: 0.0248 - mean_absolute_percentage_error: 429891.8250 - cosine_proximity: -0.9346 - val_loss: 0.0013 - val_mean_squared_error: 0.0013 - val_mean_absolute_error: 0.0267 - val_mean_absolute_percentage_error: 2020.9287 - val_cosine_proximity: -1.0000\n",
      "Epoch 4/30\n",
      "23760/23760 [==============================] - 66s 3ms/step - loss: 7.9394e-04 - mean_squared_error: 7.9394e-04 - mean_absolute_error: 0.0235 - mean_absolute_percentage_error: 332086.4660 - cosine_proximity: -0.9266 - val_loss: 0.0012 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0263 - val_mean_absolute_percentage_error: 1967.7250 - val_cosine_proximity: -1.0000\n",
      "Epoch 5/30\n",
      "23760/23760 [==============================] - 66s 3ms/step - loss: 7.2962e-04 - mean_squared_error: 7.2962e-04 - mean_absolute_error: 0.0223 - mean_absolute_percentage_error: 304812.6883 - cosine_proximity: -0.9238 - val_loss: 0.0013 - val_mean_squared_error: 0.0013 - val_mean_absolute_error: 0.0306 - val_mean_absolute_percentage_error: 1609.3311 - val_cosine_proximity: -1.0000\n",
      "Epoch 6/30\n",
      "23760/23760 [==============================] - 66s 3ms/step - loss: 6.8767e-04 - mean_squared_error: 6.8767e-04 - mean_absolute_error: 0.0216 - mean_absolute_percentage_error: 260566.9984 - cosine_proximity: -0.9191 - val_loss: 0.0012 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0290 - val_mean_absolute_percentage_error: 1670.7711 - val_cosine_proximity: -1.0000\n",
      "Epoch 7/30\n",
      "23760/23760 [==============================] - 66s 3ms/step - loss: 6.4344e-04 - mean_squared_error: 6.4344e-04 - mean_absolute_error: 0.0208 - mean_absolute_percentage_error: 256000.1226 - cosine_proximity: -0.9174 - val_loss: 0.0012 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0271 - val_mean_absolute_percentage_error: 1839.8029 - val_cosine_proximity: -1.0000\n",
      "Epoch 8/30\n",
      "23760/23760 [==============================] - 66s 3ms/step - loss: 5.9781e-04 - mean_squared_error: 5.9781e-04 - mean_absolute_error: 0.0200 - mean_absolute_percentage_error: 239412.0200 - cosine_proximity: -0.9133 - val_loss: 0.0012 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0261 - val_mean_absolute_percentage_error: 2010.1836 - val_cosine_proximity: -1.0000\n",
      "Epoch 9/30\n",
      "23760/23760 [==============================] - 66s 3ms/step - loss: 5.7865e-04 - mean_squared_error: 5.7865e-04 - mean_absolute_error: 0.0196 - mean_absolute_percentage_error: 252727.3181 - cosine_proximity: -0.9089 - val_loss: 0.0012 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0252 - val_mean_absolute_percentage_error: 2082.9924 - val_cosine_proximity: -1.0000\n",
      "Epoch 10/30\n",
      "23760/23760 [==============================] - 66s 3ms/step - loss: 5.4817e-04 - mean_squared_error: 5.4817e-04 - mean_absolute_error: 0.0191 - mean_absolute_percentage_error: 242885.6892 - cosine_proximity: -0.9053 - val_loss: 0.0012 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0250 - val_mean_absolute_percentage_error: 2067.4207 - val_cosine_proximity: -1.0000\n",
      "Epoch 11/30\n",
      "23760/23760 [==============================] - 66s 3ms/step - loss: 5.1795e-04 - mean_squared_error: 5.1795e-04 - mean_absolute_error: 0.0185 - mean_absolute_percentage_error: 240445.2489 - cosine_proximity: -0.9043 - val_loss: 0.0012 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0281 - val_mean_absolute_percentage_error: 1731.3073 - val_cosine_proximity: -1.0000\n",
      "Epoch 12/30\n",
      "23760/23760 [==============================] - 66s 3ms/step - loss: 4.8637e-04 - mean_squared_error: 4.8637e-04 - mean_absolute_error: 0.0178 - mean_absolute_percentage_error: 237086.5090 - cosine_proximity: -0.9007 - val_loss: 0.0012 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0268 - val_mean_absolute_percentage_error: 1836.9027 - val_cosine_proximity: -1.0000\n",
      "Epoch 13/30\n",
      "23760/23760 [==============================] - 66s 3ms/step - loss: 4.7477e-04 - mean_squared_error: 4.7477e-04 - mean_absolute_error: 0.0176 - mean_absolute_percentage_error: 244168.2132 - cosine_proximity: -0.8993 - val_loss: 0.0012 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0279 - val_mean_absolute_percentage_error: 1795.2369 - val_cosine_proximity: -1.0000\n",
      "Epoch 14/30\n",
      "23760/23760 [==============================] - 66s 3ms/step - loss: 4.4863e-04 - mean_squared_error: 4.4863e-04 - mean_absolute_error: 0.0171 - mean_absolute_percentage_error: 243472.1813 - cosine_proximity: -0.8973 - val_loss: 0.0012 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0265 - val_mean_absolute_percentage_error: 1875.4689 - val_cosine_proximity: -1.0000\n",
      "Epoch 15/30\n",
      "23760/23760 [==============================] - 66s 3ms/step - loss: 4.2700e-04 - mean_squared_error: 4.2700e-04 - mean_absolute_error: 0.0166 - mean_absolute_percentage_error: 222564.8002 - cosine_proximity: -0.8923 - val_loss: 0.0012 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0274 - val_mean_absolute_percentage_error: 1809.5831 - val_cosine_proximity: -1.0000\n",
      "Epoch 16/30\n",
      "23760/23760 [==============================] - 66s 3ms/step - loss: 4.1772e-04 - mean_squared_error: 4.1772e-04 - mean_absolute_error: 0.0164 - mean_absolute_percentage_error: 233597.6207 - cosine_proximity: -0.8942 - val_loss: 0.0012 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0256 - val_mean_absolute_percentage_error: 2016.3233 - val_cosine_proximity: -1.0000\n",
      "Epoch 17/30\n",
      "23760/23760 [==============================] - 66s 3ms/step - loss: 4.0288e-04 - mean_squared_error: 4.0288e-04 - mean_absolute_error: 0.0162 - mean_absolute_percentage_error: 222959.1503 - cosine_proximity: -0.8842 - val_loss: 0.0012 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0268 - val_mean_absolute_percentage_error: 1902.2067 - val_cosine_proximity: -1.0000\n",
      "Epoch 18/30\n",
      "23760/23760 [==============================] - 66s 3ms/step - loss: 3.8548e-04 - mean_squared_error: 3.8548e-04 - mean_absolute_error: 0.0157 - mean_absolute_percentage_error: 204872.0038 - cosine_proximity: -0.8865 - val_loss: 0.0012 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0275 - val_mean_absolute_percentage_error: 1845.2572 - val_cosine_proximity: -1.0000\n",
      "Epoch 19/30\n",
      "23760/23760 [==============================] - 67s 3ms/step - loss: 3.7357e-04 - mean_squared_error: 3.7357e-04 - mean_absolute_error: 0.0155 - mean_absolute_percentage_error: 229349.6805 - cosine_proximity: -0.8856 - val_loss: 0.0012 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0272 - val_mean_absolute_percentage_error: 1820.4237 - val_cosine_proximity: -1.0000\n",
      "Epoch 20/30\n",
      "23760/23760 [==============================] - 66s 3ms/step - loss: 3.6180e-04 - mean_squared_error: 3.6180e-04 - mean_absolute_error: 0.0152 - mean_absolute_percentage_error: 236224.0300 - cosine_proximity: -0.8825 - val_loss: 0.0012 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0272 - val_mean_absolute_percentage_error: 1830.4880 - val_cosine_proximity: -1.0000\n",
      "Epoch 21/30\n",
      "23760/23760 [==============================] - 66s 3ms/step - loss: 3.5360e-04 - mean_squared_error: 3.5360e-04 - mean_absolute_error: 0.0150 - mean_absolute_percentage_error: 234789.2624 - cosine_proximity: -0.8803 - val_loss: 0.0012 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0263 - val_mean_absolute_percentage_error: 1960.3614 - val_cosine_proximity: -1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      "23760/23760 [==============================] - 66s 3ms/step - loss: 3.4575e-04 - mean_squared_error: 3.4575e-04 - mean_absolute_error: 0.0149 - mean_absolute_percentage_error: 223506.8909 - cosine_proximity: -0.8793 - val_loss: 0.0012 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0294 - val_mean_absolute_percentage_error: 1695.1045 - val_cosine_proximity: -1.0000\n",
      "Epoch 23/30\n",
      "23760/23760 [==============================] - 66s 3ms/step - loss: 3.3386e-04 - mean_squared_error: 3.3386e-04 - mean_absolute_error: 0.0146 - mean_absolute_percentage_error: 205750.2334 - cosine_proximity: -0.8787 - val_loss: 0.0012 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0284 - val_mean_absolute_percentage_error: 1765.2763 - val_cosine_proximity: -1.0000\n",
      "Epoch 24/30\n",
      "23760/23760 [==============================] - 66s 3ms/step - loss: 3.2564e-04 - mean_squared_error: 3.2564e-04 - mean_absolute_error: 0.0144 - mean_absolute_percentage_error: 229049.8341 - cosine_proximity: -0.8754 - val_loss: 0.0012 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0259 - val_mean_absolute_percentage_error: 1943.6432 - val_cosine_proximity: -1.0000\n",
      "Epoch 25/30\n",
      "23760/23760 [==============================] - 66s 3ms/step - loss: 3.1210e-04 - mean_squared_error: 3.1210e-04 - mean_absolute_error: 0.0141 - mean_absolute_percentage_error: 217081.0878 - cosine_proximity: -0.8725 - val_loss: 0.0012 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0282 - val_mean_absolute_percentage_error: 1799.8248 - val_cosine_proximity: -1.0000\n",
      "Epoch 26/30\n",
      "23760/23760 [==============================] - 66s 3ms/step - loss: 3.0707e-04 - mean_squared_error: 3.0707e-04 - mean_absolute_error: 0.0140 - mean_absolute_percentage_error: 207050.1616 - cosine_proximity: -0.8709 - val_loss: 0.0012 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0267 - val_mean_absolute_percentage_error: 1910.8432 - val_cosine_proximity: -1.0000\n",
      "Epoch 27/30\n",
      "23760/23760 [==============================] - 66s 3ms/step - loss: 3.0236e-04 - mean_squared_error: 3.0236e-04 - mean_absolute_error: 0.0139 - mean_absolute_percentage_error: 211829.6244 - cosine_proximity: -0.8696 - val_loss: 0.0013 - val_mean_squared_error: 0.0013 - val_mean_absolute_error: 0.0300 - val_mean_absolute_percentage_error: 1612.8304 - val_cosine_proximity: -1.0000\n",
      "Epoch 28/30\n",
      "23760/23760 [==============================] - 66s 3ms/step - loss: 2.9985e-04 - mean_squared_error: 2.9985e-04 - mean_absolute_error: 0.0138 - mean_absolute_percentage_error: 195258.4152 - cosine_proximity: -0.8668 - val_loss: 0.0012 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0286 - val_mean_absolute_percentage_error: 1721.5454 - val_cosine_proximity: -1.0000\n",
      "Epoch 29/30\n",
      "23760/23760 [==============================] - 66s 3ms/step - loss: 2.8882e-04 - mean_squared_error: 2.8882e-04 - mean_absolute_error: 0.0135 - mean_absolute_percentage_error: 199102.9282 - cosine_proximity: -0.8708 - val_loss: 0.0012 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0271 - val_mean_absolute_percentage_error: 1899.2716 - val_cosine_proximity: -1.0000\n",
      "Epoch 30/30\n",
      "23760/23760 [==============================] - 66s 3ms/step - loss: 2.9487e-04 - mean_squared_error: 2.9487e-04 - mean_absolute_error: 0.0137 - mean_absolute_percentage_error: 214785.4315 - cosine_proximity: -0.8688 - val_loss: 0.0012 - val_mean_squared_error: 0.0012 - val_mean_absolute_error: 0.0268 - val_mean_absolute_percentage_error: 1911.6180 - val_cosine_proximity: -1.0000\n"
     ]
    }
   ],
   "source": [
    "# The model is inspired from the LeNet, 1998 paper by Le Cunn\n",
    "\n",
    "# Credits: https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "# import seaborn as sns\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 30\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(256, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape)) #Convolution\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))  #Subsampling\n",
    "model.add(Dropout(0.25))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu')) #Convolution\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))         #Subsampling\n",
    "model.add(Dropout(0.25))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "# model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu')) # Full Connection\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu')) # Full Connection\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse',#loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['mean_squared_error', 'mean_absolute_error', 'mean_absolute_percentage_error', 'cosine_proximity'])\n",
    "\n",
    "\n",
    "# train_xs, train_accels, val_xs, val_accels\n",
    "history=model.fit(train_xs, train_accels,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(val_xs, val_accels))\n",
    "\n",
    "score = model.evaluate(val_xs, val_accels, verbose=0)\n",
    "# print('Test loss:', score[0])\n",
    "# print('Test accuracy:', score[1])\n",
    "\n",
    "# plotGraph(history=history)\n",
    "# plotWeightM1(model=model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92357355]\n",
      "[0.92357355]\n",
      "[0.9310391]\n",
      "[0.9301475]\n",
      "[0.9338954]\n",
      "[0.9341978]\n",
      "[0.94233406]\n",
      "[0.93697715]\n",
      "[0.9277656]\n",
      "[0.931919]\n",
      "[0.9339071]\n",
      "[0.9301183]\n",
      "[0.9293895]\n",
      "[0.9270301]\n",
      "[0.9313618]\n",
      "[0.94097805]\n",
      "[0.9448145]\n",
      "[0.9453828]\n",
      "[0.9402479]\n",
      "[0.94632584]\n",
      "[0.94994295]\n",
      "[0.9340492]\n",
      "[0.9422594]\n",
      "[0.93306893]\n",
      "[0.94362503]\n",
      "[0.9397941]\n",
      "[0.9537025]\n",
      "[0.94687253]\n",
      "[0.9523851]\n",
      "[0.9354172]\n",
      "[0.9383295]\n",
      "[0.9428991]\n",
      "[0.94260913]\n",
      "[0.94029]\n",
      "[0.9449467]\n",
      "[0.9489774]\n",
      "[0.942226]\n",
      "[0.93854314]\n",
      "[0.9425991]\n",
      "[0.95988804]\n",
      "[0.94689965]\n",
      "[0.948667]\n",
      "[0.9394076]\n",
      "[0.9394108]\n",
      "[0.94459707]\n",
      "[0.93810683]\n",
      "[0.9388357]\n",
      "[0.9477207]\n",
      "[0.9370355]\n",
      "[0.9421201]\n",
      "[0.9484173]\n",
      "[0.94396645]\n",
      "[0.948088]\n",
      "[0.9414139]\n",
      "[0.9583285]\n",
      "[0.9663747]\n",
      "[0.95048684]\n",
      "[0.95292795]\n",
      "[0.9477265]\n",
      "[0.9556924]\n",
      "[0.9527644]\n",
      "[0.9528844]\n",
      "[0.95880514]\n",
      "[0.9665853]\n",
      "[0.9427091]\n",
      "[0.94912565]\n",
      "[0.9515617]\n",
      "[0.96681327]\n",
      "[0.96333563]\n",
      "[0.9631466]\n",
      "[0.95660615]\n",
      "[0.95560145]\n",
      "[0.96558595]\n",
      "[0.97763824]\n",
      "[0.97463447]\n",
      "[0.98999953]\n",
      "[0.98700166]\n",
      "[0.98382944]\n",
      "[0.9916441]\n",
      "[0.9790558]\n",
      "[0.9685356]\n",
      "[0.9627041]\n",
      "[0.96793133]\n",
      "[0.943886]\n",
      "[0.95342344]\n",
      "[0.9442144]\n",
      "[0.95509684]\n",
      "[0.95879275]\n",
      "[0.9559156]\n",
      "[0.9542325]\n",
      "[0.9513349]\n",
      "[0.9522948]\n",
      "[0.95300186]\n",
      "[0.94813055]\n",
      "[0.9415414]\n",
      "[0.93940866]\n",
      "[0.93264735]\n",
      "[0.93566215]\n",
      "[0.92251396]\n",
      "[0.9200164]\n",
      "[0.915039]\n",
      "[0.9238741]\n",
      "[0.90476394]\n",
      "[0.91993165]\n",
      "[0.9099057]\n",
      "[0.91145986]\n",
      "[0.92022145]\n",
      "[0.9114425]\n",
      "[0.91618896]\n",
      "[0.9241743]\n",
      "[0.9106088]\n",
      "[0.92057216]\n",
      "[0.9206505]\n",
      "[0.9085712]\n",
      "[0.9204438]\n",
      "[0.925014]\n",
      "[0.9395769]\n",
      "[0.9590481]\n",
      "[0.96299845]\n",
      "[0.9686124]\n",
      "[0.9589119]\n",
      "[0.9487808]\n",
      "[0.94530976]\n",
      "[0.93471396]\n",
      "[0.9303346]\n",
      "[0.9274143]\n",
      "[0.9238589]\n",
      "[0.91802675]\n",
      "[0.9126113]\n",
      "[0.9129979]\n",
      "[0.91688985]\n",
      "[0.9166581]\n",
      "[0.9108903]\n",
      "[0.90156496]\n",
      "[0.8984708]\n",
      "[0.8999014]\n",
      "[0.90529615]\n",
      "[0.91165096]\n",
      "[0.9138574]\n",
      "[0.9254932]\n",
      "[0.92828864]\n",
      "[0.9282427]\n",
      "[0.9110569]\n",
      "[0.9005762]\n",
      "[0.88092494]\n",
      "[0.8791093]\n",
      "[0.87473285]\n",
      "[0.86107963]\n",
      "[0.86474204]\n",
      "[0.8650788]\n",
      "[0.8623865]\n",
      "[0.85104436]\n",
      "[0.86458415]\n",
      "[0.8672497]\n",
      "[0.8708364]\n",
      "[0.8623261]\n",
      "[0.86947644]\n",
      "[0.87745875]\n",
      "[0.90166086]\n",
      "[0.91387105]\n",
      "[0.8822031]\n",
      "[0.89150643]\n",
      "[0.88545954]\n",
      "[0.91030884]\n",
      "[0.89821005]\n",
      "[0.8872493]\n",
      "[0.88205874]\n",
      "[0.86367106]\n",
      "[0.8707646]\n",
      "[0.850026]\n",
      "[0.84275156]\n",
      "[0.8319595]\n",
      "[0.8219217]\n",
      "[0.8204057]\n",
      "[0.8229427]\n",
      "[0.79350805]\n",
      "[0.7840077]\n",
      "[0.7704222]\n",
      "[0.7479197]\n",
      "[0.72855395]\n",
      "[0.7314589]\n",
      "[0.7406634]\n",
      "[0.73661315]\n",
      "[0.7195626]\n",
      "[0.7203924]\n",
      "[0.71316713]\n",
      "[0.72594583]\n",
      "[0.73706394]\n",
      "[0.74367577]\n",
      "[0.74674004]\n",
      "[0.7457792]\n",
      "[0.75394696]\n",
      "[0.7480418]\n",
      "[0.74752545]\n",
      "[0.7257994]\n",
      "[0.73646235]\n",
      "[0.75342077]\n",
      "[0.77841955]\n",
      "[0.8143443]\n",
      "[0.83158535]\n",
      "[0.8549231]\n",
      "[0.868442]\n",
      "[0.85895497]\n",
      "[0.8365425]\n",
      "[0.8095643]\n",
      "[0.81338644]\n",
      "[0.8365186]\n",
      "[0.8482044]\n",
      "[0.87796515]\n",
      "[0.88283074]\n",
      "[0.8600529]\n",
      "[0.8161016]\n",
      "[0.8269331]\n",
      "[0.822992]\n",
      "[0.8294791]\n",
      "[0.82440877]\n",
      "[0.8439457]\n",
      "[0.8682041]\n",
      "[0.8441302]\n",
      "[0.859312]\n",
      "[0.84792715]\n",
      "[0.8761638]\n",
      "[0.86791134]\n",
      "[0.84269667]\n",
      "[0.8435793]\n",
      "[0.8634543]\n",
      "[0.89717454]\n",
      "[0.9356946]\n",
      "[0.99599713]\n",
      "[1.0167785]\n",
      "[1.0339339]\n",
      "[1.0642612]\n",
      "[1.0840813]\n",
      "[1.1420026]\n",
      "[1.1634926]\n",
      "[1.2290145]\n",
      "[1.1966968]\n",
      "[1.1835644]\n",
      "[1.0982788]\n",
      "[1.0384785]\n",
      "[1.01977]\n",
      "[0.959578]\n",
      "[0.97629225]\n",
      "[1.0454319]\n",
      "[1.0531812]\n",
      "[1.0263866]\n",
      "[0.99493665]\n",
      "[1.0072173]\n",
      "[1.0026139]\n",
      "[1.0118704]\n",
      "[0.9863667]\n",
      "[0.9837937]\n",
      "[0.97154677]\n",
      "[0.9626454]\n",
      "[0.9596074]\n",
      "[0.95364636]\n",
      "[0.9561902]\n",
      "[0.93159264]\n",
      "[0.94842505]\n",
      "[0.93144876]\n",
      "[0.93686867]\n",
      "[0.9241271]\n",
      "[0.9118338]\n",
      "[0.90270805]\n",
      "[0.9056711]\n",
      "[0.9051896]\n",
      "[0.89212143]\n",
      "[0.87769675]\n",
      "[0.8811056]\n",
      "[0.8629304]\n",
      "[0.8605791]\n",
      "[0.85038817]\n",
      "[0.8503183]\n",
      "[0.83899415]\n",
      "[0.84407043]\n",
      "[0.84660786]\n",
      "[0.83424664]\n",
      "[0.8290462]\n",
      "[0.8138602]\n",
      "[0.8335827]\n",
      "[0.82630485]\n",
      "[0.82564825]\n",
      "[0.8310502]\n",
      "[0.84167564]\n",
      "[0.8475244]\n",
      "[0.86636657]\n",
      "[0.85709214]\n",
      "[0.8758698]\n",
      "[0.8664634]\n",
      "[0.8893201]\n",
      "[0.88245296]\n",
      "[0.9067545]\n",
      "[0.916322]\n",
      "[0.9202887]\n",
      "[0.90955347]\n",
      "[0.92365944]\n",
      "[0.9192844]\n",
      "[0.91451967]\n",
      "[0.9344861]\n",
      "[0.9293363]\n",
      "[0.95008814]\n",
      "[0.93010783]\n",
      "[0.9547901]\n",
      "[0.94410104]\n",
      "[0.9443989]\n",
      "[0.95232236]\n",
      "[0.9644196]\n",
      "[0.9682893]\n",
      "[0.9781855]\n",
      "[0.96252066]\n",
      "[0.9830696]\n",
      "[0.98204786]\n",
      "[1.0007803]\n",
      "[1.0048856]\n",
      "[1.0234174]\n",
      "[1.048122]\n",
      "[1.0252248]\n",
      "[1.0299866]\n",
      "[1.0306106]\n",
      "[1.0453371]\n",
      "[1.0488528]\n",
      "[1.0647415]\n",
      "[1.0784332]\n",
      "[1.1112446]\n",
      "[1.1344757]\n",
      "[1.1273502]\n",
      "[1.1241584]\n",
      "[1.1441549]\n",
      "[1.1431059]\n",
      "[1.1465023]\n",
      "[1.1531982]\n",
      "[1.1678956]\n",
      "[1.1774986]\n",
      "[1.1893216]\n",
      "[1.2158031]\n",
      "[1.2449013]\n",
      "[1.2680755]\n",
      "[1.2864035]\n",
      "[1.3209008]\n",
      "[1.3313009]\n",
      "[1.3562062]\n",
      "[1.3692762]\n",
      "[1.3714597]\n",
      "[1.370057]\n",
      "[1.3641974]\n",
      "[1.3645078]\n",
      "[1.375003]\n",
      "[1.3705657]\n",
      "[1.3830924]\n",
      "[1.3837837]\n",
      "[1.3706061]\n",
      "[1.3627698]\n",
      "[1.34656]\n",
      "[1.3507036]\n",
      "[1.3533473]\n",
      "[1.3483729]\n",
      "[1.3463407]\n",
      "[1.3468617]\n",
      "[1.3425999]\n",
      "[1.3328763]\n",
      "[1.3277127]\n",
      "[1.3588235]\n",
      "[1.3306398]\n",
      "[1.33572]\n",
      "[1.359622]\n",
      "[1.3321513]\n",
      "[1.3348776]\n",
      "[1.31162]\n",
      "[1.286075]\n",
      "[1.3127716]\n",
      "[1.3437306]\n",
      "[1.3520048]\n",
      "[1.4002119]\n",
      "[1.4235718]\n",
      "[1.4195621]\n",
      "[1.3825723]\n",
      "[1.381219]\n",
      "[1.3690385]\n",
      "[1.3706627]\n",
      "[1.3709453]\n",
      "[1.3364332]\n",
      "[1.338435]\n",
      "[1.3284469]\n",
      "[1.3391124]\n",
      "[1.3389394]\n",
      "[1.296155]\n",
      "[1.227619]\n",
      "[1.268974]\n",
      "[1.2880924]\n",
      "[1.2478769]\n",
      "[1.2383322]\n",
      "[1.2607045]\n",
      "[1.2887259]\n",
      "[1.3293341]\n",
      "[1.3731195]\n",
      "[1.3611574]\n",
      "[1.3551658]\n",
      "[1.3309369]\n",
      "[1.3600179]\n",
      "[1.3449199]\n",
      "[1.3116074]\n",
      "[1.3144517]\n",
      "[1.3136162]\n",
      "[1.3415769]\n",
      "[1.3164779]\n",
      "[1.2834789]\n",
      "[1.2527516]\n",
      "[1.2733141]\n",
      "[1.2763101]\n",
      "[1.2891037]\n",
      "[1.2677023]\n",
      "[1.3220471]\n",
      "[1.3370636]\n",
      "[1.319204]\n",
      "[1.2914317]\n",
      "[1.2886823]\n",
      "[1.3080208]\n",
      "[1.3143456]\n",
      "[1.3255308]\n",
      "[1.3459607]\n",
      "[1.2954897]\n",
      "[1.3518258]\n",
      "[1.3438071]\n",
      "[1.3301889]\n",
      "[1.3843293]\n",
      "[1.3553054]\n",
      "[1.2707816]\n",
      "[1.2966286]\n",
      "[1.3336034]\n",
      "[1.4060547]\n",
      "[1.4745098]\n",
      "[1.5178976]\n",
      "[1.5731158]\n",
      "[1.576893]\n",
      "[1.5992246]\n",
      "[1.6033586]\n",
      "[1.6190901]\n",
      "[1.6013478]\n",
      "[1.591466]\n",
      "[1.5948329]\n",
      "[1.6320802]\n",
      "[1.6587751]\n",
      "[1.6477685]\n",
      "[1.7029836]\n",
      "[1.7431957]\n",
      "[1.8917855]\n",
      "[1.9616673]\n",
      "[2.0167127]\n",
      "[2.02814]\n",
      "[2.0636706]\n",
      "[2.110657]\n",
      "[2.2280586]\n",
      "[2.3639114]\n",
      "[2.4639022]\n",
      "[2.685708]\n",
      "[2.76365]\n",
      "[2.8592691]\n",
      "[2.9558606]\n",
      "[2.983342]\n",
      "[3.2166684]\n",
      "[3.3073065]\n",
      "[3.270742]\n",
      "[3.7331123]\n",
      "[3.9293516]\n",
      "[4.0053616]\n",
      "[4.06205]\n",
      "[4.2649136]\n",
      "[4.337888]\n",
      "[4.3596253]\n",
      "[4.4200063]\n",
      "[4.5125837]\n",
      "[4.5460014]\n",
      "[4.5233364]\n",
      "[4.4941955]\n",
      "[4.4982486]\n",
      "[4.5160336]\n",
      "[4.5245953]\n",
      "[4.417109]\n",
      "[4.42547]\n",
      "[4.4219527]\n",
      "[4.4052186]\n",
      "[4.3705196]\n",
      "[4.3673573]\n",
      "[4.3751907]\n",
      "[4.441688]\n",
      "[4.5124846]\n",
      "[4.539051]\n",
      "[4.6165376]\n",
      "[4.620568]\n",
      "[4.664722]\n",
      "[4.6845293]\n",
      "[4.6924257]\n",
      "[4.654179]\n",
      "[4.616378]\n",
      "[4.646823]\n",
      "[4.682429]\n",
      "[4.6911473]\n",
      "[4.6978917]\n",
      "[4.701402]\n",
      "[4.70392]\n"
     ]
    }
   ],
   "source": [
    "# To try predict acceleration using train data\n",
    "pred = model.predict(train_xs)\n",
    "\n",
    "#Print acceleration first n frames\n",
    "for i in pred[0:500]:\n",
    "    print(i*180/scipy.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"save/model_accel.ckpt\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_MNIST.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
